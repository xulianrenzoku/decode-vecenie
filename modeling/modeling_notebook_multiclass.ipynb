{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-17T14:41:34.500838Z","iopub.execute_input":"2023-08-17T14:41:34.501272Z","iopub.status.idle":"2023-08-17T14:41:34.522228Z","shell.execute_reply.started":"2023-08-17T14:41:34.501233Z","shell.execute_reply":"2023-08-17T14:41:34.520867Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/draft-guide-by-sam-vecenie/draft_guide_data.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport time\nfrom tqdm.auto import tqdm","metadata":{"execution":{"iopub.status.busy":"2023-08-17T14:41:34.530805Z","iopub.execute_input":"2023-08-17T14:41:34.531182Z","iopub.status.idle":"2023-08-17T14:41:34.633430Z","shell.execute_reply.started":"2023-08-17T14:41:34.531129Z","shell.execute_reply":"2023-08-17T14:41:34.632256Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"pd.set_option('display.max_rows', None)","metadata":{"execution":{"iopub.status.busy":"2023-08-17T14:41:34.634884Z","iopub.execute_input":"2023-08-17T14:41:34.635330Z","iopub.status.idle":"2023-08-17T14:41:34.642432Z","shell.execute_reply.started":"2023-08-17T14:41:34.635289Z","shell.execute_reply":"2023-08-17T14:41:34.641290Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Read Data","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/draft-guide-by-sam-vecenie/draft_guide_data.csv')\nprint(df.shape)\ndf.head(1)","metadata":{"execution":{"iopub.status.busy":"2023-08-17T14:41:34.646250Z","iopub.execute_input":"2023-08-17T14:41:34.647033Z","iopub.status.idle":"2023-08-17T14:41:34.733788Z","shell.execute_reply.started":"2023-08-17T14:41:34.646986Z","shell.execute_reply":"2023-08-17T14:41:34.732680Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"(288, 13)\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"   RANK       PLAYER      SCHOOL/TEAM POS  AGE   HT WING  TIER  \\\n0     1  LaMelo Ball  Illawarra Hawks   G   19  6-6  6-9     5   \n\n                                           STRENGTHS  \\\n0  Everything starts with Ball’s elite-level feel...   \n\n                                          WEAKNESSES  \\\n0  The defense isn’t a sure thing, though, becaus...   \n\n                                             SUMMARY     TIER_DESCRIP  year  \n0  Ball should enter the NBA as one of the most c...  All-Star Upside  2020  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RANK</th>\n      <th>PLAYER</th>\n      <th>SCHOOL/TEAM</th>\n      <th>POS</th>\n      <th>AGE</th>\n      <th>HT</th>\n      <th>WING</th>\n      <th>TIER</th>\n      <th>STRENGTHS</th>\n      <th>WEAKNESSES</th>\n      <th>SUMMARY</th>\n      <th>TIER_DESCRIP</th>\n      <th>year</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>LaMelo Ball</td>\n      <td>Illawarra Hawks</td>\n      <td>G</td>\n      <td>19</td>\n      <td>6-6</td>\n      <td>6-9</td>\n      <td>5</td>\n      <td>Everything starts with Ball’s elite-level feel...</td>\n      <td>The defense isn’t a sure thing, though, becaus...</td>\n      <td>Ball should enter the NBA as one of the most c...</td>\n      <td>All-Star Upside</td>\n      <td>2020</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Add Strengths and Weaknesses\ndf['full_text'] = df[['STRENGTHS', 'WEAKNESSES']].apply(lambda x: x[0] + ' ' + x[1], axis=1)\ndf.head(1)","metadata":{"execution":{"iopub.status.busy":"2023-08-17T14:41:34.735522Z","iopub.execute_input":"2023-08-17T14:41:34.736336Z","iopub.status.idle":"2023-08-17T14:41:34.761783Z","shell.execute_reply.started":"2023-08-17T14:41:34.736297Z","shell.execute_reply":"2023-08-17T14:41:34.760184Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"   RANK       PLAYER      SCHOOL/TEAM POS  AGE   HT WING  TIER  \\\n0     1  LaMelo Ball  Illawarra Hawks   G   19  6-6  6-9     5   \n\n                                           STRENGTHS  \\\n0  Everything starts with Ball’s elite-level feel...   \n\n                                          WEAKNESSES  \\\n0  The defense isn’t a sure thing, though, becaus...   \n\n                                             SUMMARY     TIER_DESCRIP  year  \\\n0  Ball should enter the NBA as one of the most c...  All-Star Upside  2020   \n\n                                           full_text  \n0  Everything starts with Ball’s elite-level feel...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RANK</th>\n      <th>PLAYER</th>\n      <th>SCHOOL/TEAM</th>\n      <th>POS</th>\n      <th>AGE</th>\n      <th>HT</th>\n      <th>WING</th>\n      <th>TIER</th>\n      <th>STRENGTHS</th>\n      <th>WEAKNESSES</th>\n      <th>SUMMARY</th>\n      <th>TIER_DESCRIP</th>\n      <th>year</th>\n      <th>full_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>LaMelo Ball</td>\n      <td>Illawarra Hawks</td>\n      <td>G</td>\n      <td>19</td>\n      <td>6-6</td>\n      <td>6-9</td>\n      <td>5</td>\n      <td>Everything starts with Ball’s elite-level feel...</td>\n      <td>The defense isn’t a sure thing, though, becaus...</td>\n      <td>Ball should enter the NBA as one of the most c...</td>\n      <td>All-Star Upside</td>\n      <td>2020</td>\n      <td>Everything starts with Ball’s elite-level feel...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df['TIER'] = df['TIER'] - 1","metadata":{"execution":{"iopub.status.busy":"2023-08-17T14:41:34.763419Z","iopub.execute_input":"2023-08-17T14:41:34.764046Z","iopub.status.idle":"2023-08-17T14:41:34.775418Z","shell.execute_reply.started":"2023-08-17T14:41:34.764008Z","shell.execute_reply":"2023-08-17T14:41:34.774301Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## Preprocessing","metadata":{}},{"cell_type":"code","source":"# test = df.sample(50, random_state=42)\ndf_2023 = df[df['year'] == 2023]\n# test.sort_values('TIER', ascending=False).head()","metadata":{"execution":{"iopub.status.busy":"2023-08-17T14:41:34.777400Z","iopub.execute_input":"2023-08-17T14:41:34.778195Z","iopub.status.idle":"2023-08-17T14:41:34.788404Z","shell.execute_reply.started":"2023-08-17T14:41:34.778155Z","shell.execute_reply":"2023-08-17T14:41:34.787265Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"val = df_2023.sample(40, random_state=42)\ntest = df_2023[~df_2023.index.isin(val.index)]\nval.shape, test.shape","metadata":{"execution":{"iopub.status.busy":"2023-08-17T14:41:34.790269Z","iopub.execute_input":"2023-08-17T14:41:34.790990Z","iopub.status.idle":"2023-08-17T14:41:34.804424Z","shell.execute_reply.started":"2023-08-17T14:41:34.790952Z","shell.execute_reply":"2023-08-17T14:41:34.802977Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"((40, 14), (35, 14))"},"metadata":{}}]},{"cell_type":"code","source":"train = df[~df.index.isin(df_2023.index)]\\\n        .reset_index().drop('index', axis=1)\ntrain.shape","metadata":{"execution":{"iopub.status.busy":"2023-08-17T14:41:35.464381Z","iopub.execute_input":"2023-08-17T14:41:35.464772Z","iopub.status.idle":"2023-08-17T14:41:35.477775Z","shell.execute_reply.started":"2023-08-17T14:41:35.464741Z","shell.execute_reply":"2023-08-17T14:41:35.476135Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"(213, 14)"},"metadata":{}}]},{"cell_type":"code","source":"# data augmentation\ntrain_copy = train.copy()\ntrain_copy['full_text'] = train_copy[['STRENGTHS', 'WEAKNESSES']].apply(lambda x: x[1] + ' ' + x[0], axis=1)\ntrain = pd.concat([train, train_copy])\\\n          .reset_index().drop('index', axis=1)\ntrain.shape","metadata":{"execution":{"iopub.status.busy":"2023-08-17T14:41:38.243249Z","iopub.execute_input":"2023-08-17T14:41:38.243674Z","iopub.status.idle":"2023-08-17T14:41:38.268611Z","shell.execute_reply.started":"2023-08-17T14:41:38.243640Z","shell.execute_reply":"2023-08-17T14:41:38.266816Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"(426, 14)"},"metadata":{}}]},{"cell_type":"code","source":"train_count_dict = train.groupby('TIER')['PLAYER'].count().to_dict()\ntrain_count_dict","metadata":{"execution":{"iopub.status.busy":"2023-08-17T14:41:38.888010Z","iopub.execute_input":"2023-08-17T14:41:38.888855Z","iopub.status.idle":"2023-08-17T14:41:38.897995Z","shell.execute_reply.started":"2023-08-17T14:41:38.888803Z","shell.execute_reply":"2023-08-17T14:41:38.896896Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"{0: 144, 1: 162, 2: 68, 3: 30, 4: 22}"},"metadata":{}}]},{"cell_type":"code","source":"max_n = max(train_count_dict.values())\n\nfor i in range(5):\n    diff = max_n - train_count_dict[i]\n    if diff != 0:\n        random_sample = train[train['TIER'] == i].sample(diff, \n                                                         random_state=42,\n                                                         replace=True)\n        train = pd.concat([train, random_sample])\\\n                  .reset_index().drop('index', axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-08-17T14:41:39.327584Z","iopub.execute_input":"2023-08-17T14:41:39.328467Z","iopub.status.idle":"2023-08-17T14:41:39.363151Z","shell.execute_reply.started":"2023-08-17T14:41:39.328418Z","shell.execute_reply":"2023-08-17T14:41:39.361983Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"train.groupby('TIER')['PLAYER'].count().to_dict()","metadata":{"execution":{"iopub.status.busy":"2023-08-17T14:41:39.905307Z","iopub.execute_input":"2023-08-17T14:41:39.905720Z","iopub.status.idle":"2023-08-17T14:41:39.916283Z","shell.execute_reply.started":"2023-08-17T14:41:39.905683Z","shell.execute_reply":"2023-08-17T14:41:39.914719Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"{0: 162, 1: 162, 2: 162, 3: 162, 4: 162}"},"metadata":{}}]},{"cell_type":"code","source":"labels = df['TIER_DESCRIP'].unique()\nid2label = {row[0]: row[1]\n            for row in df[['TIER', 'TIER_DESCRIP']].drop_duplicates().values}\nlabel2id = {row[1]: row[0]\n            for row in df[['TIER', 'TIER_DESCRIP']].drop_duplicates().values}","metadata":{"execution":{"iopub.status.busy":"2023-08-17T14:41:40.306271Z","iopub.execute_input":"2023-08-17T14:41:40.307171Z","iopub.status.idle":"2023-08-17T14:41:40.321350Z","shell.execute_reply.started":"2023-08-17T14:41:40.307127Z","shell.execute_reply":"2023-08-17T14:41:40.319887Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## Preprocessing\n","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch.nn import functional as F\nfrom transformers import (\n    AdamW,\n    AutoTokenizer, \n    AutoModelForSequenceClassification,\n    DataCollatorWithPadding,\n    get_scheduler,\n    TrainingArguments,\n    Trainer\n)\nfrom datasets import Dataset","metadata":{"execution":{"iopub.status.busy":"2023-08-17T14:41:41.058051Z","iopub.execute_input":"2023-08-17T14:41:41.059074Z","iopub.status.idle":"2023-08-17T14:41:50.340652Z","shell.execute_reply.started":"2023-08-17T14:41:41.059033Z","shell.execute_reply":"2023-08-17T14:41:50.339552Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"MODEL = 'bert-base-uncased'\ntokenizer = AutoTokenizer.from_pretrained(MODEL)\nmodel = AutoModelForSequenceClassification\\\n        .from_pretrained(MODEL, \n                         id2label=id2label,\n                         label2id=label2id)\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2023-08-17T14:41:50.342670Z","iopub.execute_input":"2023-08-17T14:41:50.343527Z","iopub.status.idle":"2023-08-17T14:41:51.774584Z","shell.execute_reply.started":"2023-08-17T14:41:50.343485Z","shell.execute_reply":"2023-08-17T14:41:51.773578Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"model","metadata":{"execution":{"iopub.status.busy":"2023-08-17T14:41:58.221454Z","iopub.execute_input":"2023-08-17T14:41:58.221975Z","iopub.status.idle":"2023-08-17T14:41:58.233143Z","shell.execute_reply.started":"2023-08-17T14:41:58.221929Z","shell.execute_reply":"2023-08-17T14:41:58.232013Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"BertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=5, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"def preprocess_function(examples):\n    tokens = tokenizer(examples['full_text'], \n                       truncation=True, \n                       max_length=512)\n    if 'TIER' in examples:\n        labels_matrix = [[0.0 if examples['TIER'][i] != j else 1.0\n                          for j in range(len(labels))]\n                         for i in range(len(examples['TIER']))]\n        return {**tokens, \"labels\": labels_matrix}\n    else:\n        return tokens","metadata":{"execution":{"iopub.status.busy":"2023-08-17T14:42:29.670563Z","iopub.execute_input":"2023-08-17T14:42:29.670993Z","iopub.status.idle":"2023-08-17T14:42:29.680162Z","shell.execute_reply.started":"2023-08-17T14:42:29.670955Z","shell.execute_reply":"2023-08-17T14:42:29.678896Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"train_dataset = (\n    Dataset.from_pandas(train[['PLAYER', 'full_text', 'TIER']])\n    .map(preprocess_function, batched=True)\n    .remove_columns(['TIER'])\n    .shuffle(seed=42)\n)\n\nval_dataset = (\n    Dataset.from_pandas(val[['PLAYER', 'full_text', 'TIER']])\n    .map(preprocess_function, batched=True)\n    .remove_columns(['TIER'])\n    .shuffle(seed=42)\n)\n\ntest_dataset = (\n    Dataset.from_pandas(test[['PLAYER', 'full_text', 'TIER']])\n    .map(preprocess_function, batched=True)\n    .remove_columns(['TIER'])\n    .shuffle(seed=42)\n)","metadata":{"execution":{"iopub.status.busy":"2023-08-17T14:42:30.157455Z","iopub.execute_input":"2023-08-17T14:42:30.157900Z","iopub.status.idle":"2023-08-17T14:42:33.457727Z","shell.execute_reply.started":"2023-08-17T14:42:30.157869Z","shell.execute_reply":"2023-08-17T14:42:33.456674Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2736aea059064dc6980b4c24aab8a27c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7985c93284fc4475837850d28d011dbf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83a07b6740e6442db8982658d72a4994"}},"metadata":{}}]},{"cell_type":"code","source":"example = train_dataset[0]\nexample['PLAYER'], example['labels']","metadata":{"execution":{"iopub.status.busy":"2023-08-17T14:42:33.459603Z","iopub.execute_input":"2023-08-17T14:42:33.460387Z","iopub.status.idle":"2023-08-17T14:42:33.469759Z","shell.execute_reply.started":"2023-08-17T14:42:33.460348Z","shell.execute_reply":"2023-08-17T14:42:33.468970Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"('Kessler Edwards', [0.0, 1.0, 0.0, 0.0, 0.0])"},"metadata":{}}]},{"cell_type":"markdown","source":"## Modeling","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import f1_score, accuracy_score, log_loss, mean_squared_error\nfrom sklearn.metrics import classification_report","metadata":{"execution":{"iopub.status.busy":"2023-08-17T14:42:34.769502Z","iopub.execute_input":"2023-08-17T14:42:34.770813Z","iopub.status.idle":"2023-08-17T14:42:34.776664Z","shell.execute_reply.started":"2023-08-17T14:42:34.770766Z","shell.execute_reply":"2023-08-17T14:42:34.775445Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"class CustomTrainer(Trainer):\n    def compute_loss(self, model, inputs, return_outputs=False):\n        # replace with regression loss\n        labels = inputs.pop(\"labels\")\n        outputs = model(**inputs)\n        logits = outputs.get(\"logits\")\n        loss = F.cross_entropy(F.softmax(logits), labels)\n        return (loss, outputs) if return_outputs else loss\n    \ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = F.softmax(torch.tensor(logits))\n    labels_adj = [np.argmax(l) for l in labels]\n    predictions_adj = [np.sum([j * p[j] for j in range(5)]) for p in predictions]\n    return {\"RMSE\": log_loss(labels, predictions)}","metadata":{"execution":{"iopub.status.busy":"2023-08-17T14:42:35.600813Z","iopub.execute_input":"2023-08-17T14:42:35.601505Z","iopub.status.idle":"2023-08-17T14:42:35.612554Z","shell.execute_reply.started":"2023-08-17T14:42:35.601466Z","shell.execute_reply":"2023-08-17T14:42:35.610902Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"os.environ[\"WANDB_DISABLED\"] = \"true\"\n\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2023-08-17T14:42:37.074137Z","iopub.execute_input":"2023-08-17T14:42:37.074860Z","iopub.status.idle":"2023-08-17T14:42:37.079890Z","shell.execute_reply.started":"2023-08-17T14:42:37.074825Z","shell.execute_reply":"2023-08-17T14:42:37.078678Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"CONFIG = {\n    \"weight_decay\": 0.01,\n    \"num_train_epochs\": 10.0,\n    \"load_best_model_at_end\": True,\n    \"metric_for_best_model\": 'eval_loss',\n    \"lr_scheduler_type\": 'cosine_with_restarts',\n}","metadata":{"execution":{"iopub.status.busy":"2023-08-17T14:43:44.723026Z","iopub.execute_input":"2023-08-17T14:43:44.723445Z","iopub.status.idle":"2023-08-17T14:43:44.728828Z","shell.execute_reply.started":"2023-08-17T14:43:44.723411Z","shell.execute_reply":"2023-08-17T14:43:44.727550Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"run_name = f\"fpell-{int(time.time())}\"\n\nprint(\"=\" * 50)\nprint(f\"Starting run: {run_name}\")\nprint(\"=\" * 50)\n\ntraining_args = TrainingArguments(\n    run_name=run_name,\n    output_dir=\"./results\",\n    save_total_limit=5,\n    evaluation_strategy=\"steps\",\n    eval_steps=50,\n    logging_steps=50,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    **CONFIG,\n)\n\ntrainer = CustomTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-08-17T14:43:49.031684Z","iopub.execute_input":"2023-08-17T14:43:49.032068Z","iopub.status.idle":"2023-08-17T14:51:47.231277Z","shell.execute_reply.started":"2023-08-17T14:43:49.032037Z","shell.execute_reply":"2023-08-17T14:51:47.230253Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"},{"name":"stdout","text":"==================================================\nStarting run: fpell-1692283429\n==================================================\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\nYou're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n/tmp/ipykernel_622/1591327229.py:7: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  loss = F.cross_entropy(F.softmax(logits), labels)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1020' max='1020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1020/1020 07:54, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rmse</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>1.590200</td>\n      <td>1.624614</td>\n      <td>1.806699</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>1.532800</td>\n      <td>1.510649</td>\n      <td>1.577423</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>1.499200</td>\n      <td>1.563524</td>\n      <td>1.671481</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>1.458200</td>\n      <td>1.596640</td>\n      <td>1.726060</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>1.386400</td>\n      <td>1.478005</td>\n      <td>1.579279</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>1.408000</td>\n      <td>1.569886</td>\n      <td>1.885075</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>1.330000</td>\n      <td>1.518916</td>\n      <td>1.826413</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>1.256900</td>\n      <td>1.511157</td>\n      <td>1.872226</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>1.210600</td>\n      <td>1.524825</td>\n      <td>1.973627</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>1.163300</td>\n      <td>1.490005</td>\n      <td>2.055536</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>1.124600</td>\n      <td>1.509762</td>\n      <td>2.542820</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>1.091200</td>\n      <td>1.548561</td>\n      <td>2.875867</td>\n    </tr>\n    <tr>\n      <td>650</td>\n      <td>1.031900</td>\n      <td>1.612693</td>\n      <td>3.209887</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>1.003700</td>\n      <td>1.624654</td>\n      <td>3.331715</td>\n    </tr>\n    <tr>\n      <td>750</td>\n      <td>0.975100</td>\n      <td>1.593958</td>\n      <td>3.489594</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>0.986100</td>\n      <td>1.559155</td>\n      <td>3.208791</td>\n    </tr>\n    <tr>\n      <td>850</td>\n      <td>0.962900</td>\n      <td>1.590307</td>\n      <td>3.413481</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>0.945900</td>\n      <td>1.596176</td>\n      <td>3.540206</td>\n    </tr>\n    <tr>\n      <td>950</td>\n      <td>0.943000</td>\n      <td>1.584889</td>\n      <td>3.458719</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.943800</td>\n      <td>1.589092</td>\n      <td>3.495403</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_622/1591327229.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  predictions = F.softmax(torch.tensor(logits))\n/tmp/ipykernel_622/1591327229.py:7: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  loss = F.cross_entropy(F.softmax(logits), labels)\n/tmp/ipykernel_622/1591327229.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  predictions = F.softmax(torch.tensor(logits))\n/tmp/ipykernel_622/1591327229.py:7: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  loss = F.cross_entropy(F.softmax(logits), labels)\n/tmp/ipykernel_622/1591327229.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  predictions = F.softmax(torch.tensor(logits))\n/tmp/ipykernel_622/1591327229.py:7: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  loss = F.cross_entropy(F.softmax(logits), labels)\n/tmp/ipykernel_622/1591327229.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  predictions = F.softmax(torch.tensor(logits))\n/tmp/ipykernel_622/1591327229.py:7: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  loss = F.cross_entropy(F.softmax(logits), labels)\n/tmp/ipykernel_622/1591327229.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  predictions = F.softmax(torch.tensor(logits))\n/tmp/ipykernel_622/1591327229.py:7: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  loss = F.cross_entropy(F.softmax(logits), labels)\n/tmp/ipykernel_622/1591327229.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  predictions = F.softmax(torch.tensor(logits))\n/tmp/ipykernel_622/1591327229.py:7: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  loss = F.cross_entropy(F.softmax(logits), labels)\n/tmp/ipykernel_622/1591327229.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  predictions = F.softmax(torch.tensor(logits))\n/tmp/ipykernel_622/1591327229.py:7: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  loss = F.cross_entropy(F.softmax(logits), labels)\n/tmp/ipykernel_622/1591327229.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  predictions = F.softmax(torch.tensor(logits))\n/tmp/ipykernel_622/1591327229.py:7: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  loss = F.cross_entropy(F.softmax(logits), labels)\n/tmp/ipykernel_622/1591327229.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  predictions = F.softmax(torch.tensor(logits))\n/tmp/ipykernel_622/1591327229.py:7: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  loss = F.cross_entropy(F.softmax(logits), labels)\n/tmp/ipykernel_622/1591327229.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  predictions = F.softmax(torch.tensor(logits))\n/tmp/ipykernel_622/1591327229.py:7: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  loss = F.cross_entropy(F.softmax(logits), labels)\n/tmp/ipykernel_622/1591327229.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  predictions = F.softmax(torch.tensor(logits))\n/tmp/ipykernel_622/1591327229.py:7: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  loss = F.cross_entropy(F.softmax(logits), labels)\n/tmp/ipykernel_622/1591327229.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  predictions = F.softmax(torch.tensor(logits))\n/tmp/ipykernel_622/1591327229.py:7: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  loss = F.cross_entropy(F.softmax(logits), labels)\n/tmp/ipykernel_622/1591327229.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  predictions = F.softmax(torch.tensor(logits))\n/tmp/ipykernel_622/1591327229.py:7: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  loss = F.cross_entropy(F.softmax(logits), labels)\n/tmp/ipykernel_622/1591327229.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  predictions = F.softmax(torch.tensor(logits))\n/tmp/ipykernel_622/1591327229.py:7: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  loss = F.cross_entropy(F.softmax(logits), labels)\n/tmp/ipykernel_622/1591327229.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  predictions = F.softmax(torch.tensor(logits))\n/tmp/ipykernel_622/1591327229.py:7: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  loss = F.cross_entropy(F.softmax(logits), labels)\n/tmp/ipykernel_622/1591327229.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  predictions = F.softmax(torch.tensor(logits))\n/tmp/ipykernel_622/1591327229.py:7: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  loss = F.cross_entropy(F.softmax(logits), labels)\n/tmp/ipykernel_622/1591327229.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  predictions = F.softmax(torch.tensor(logits))\n/tmp/ipykernel_622/1591327229.py:7: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  loss = F.cross_entropy(F.softmax(logits), labels)\n/tmp/ipykernel_622/1591327229.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  predictions = F.softmax(torch.tensor(logits))\n/tmp/ipykernel_622/1591327229.py:7: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  loss = F.cross_entropy(F.softmax(logits), labels)\n/tmp/ipykernel_622/1591327229.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  predictions = F.softmax(torch.tensor(logits))\n/tmp/ipykernel_622/1591327229.py:7: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  loss = F.cross_entropy(F.softmax(logits), labels)\n/tmp/ipykernel_622/1591327229.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  predictions = F.softmax(torch.tensor(logits))\n/tmp/ipykernel_622/1591327229.py:7: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  loss = F.cross_entropy(F.softmax(logits), labels)\n","output_type":"stream"},{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1020, training_loss=1.1870407366285136, metrics={'train_runtime': 475.2026, 'train_samples_per_second': 17.045, 'train_steps_per_second': 2.146, 'total_flos': 2131256953958400.0, 'train_loss': 1.1870407366285136, 'epoch': 10.0})"},"metadata":{}}]},{"cell_type":"code","source":"temp = trainer.predict(train_dataset)\nlog_loss(temp[1], F.softmax(torch.tensor(temp[0])))","metadata":{"execution":{"iopub.status.busy":"2023-08-17T14:51:47.233434Z","iopub.execute_input":"2023-08-17T14:51:47.233925Z","iopub.status.idle":"2023-08-17T14:52:02.712122Z","shell.execute_reply.started":"2023-08-17T14:51:47.233886Z","shell.execute_reply":"2023-08-17T14:52:02.710974Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_622/1591327229.py:7: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  loss = F.cross_entropy(F.softmax(logits), labels)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_622/1591327229.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  predictions = F.softmax(torch.tensor(logits))\n/tmp/ipykernel_622/791149759.py:2: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  log_loss(temp[1], F.softmax(torch.tensor(temp[0])))\n","output_type":"stream"},{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"0.5141349176457469"},"metadata":{}}]},{"cell_type":"code","source":"temp = trainer.predict(val_dataset)\nlog_loss(temp[1], F.softmax(torch.tensor(temp[0])))","metadata":{"execution":{"iopub.status.busy":"2023-08-17T14:52:02.714111Z","iopub.execute_input":"2023-08-17T14:52:02.714563Z","iopub.status.idle":"2023-08-17T14:52:03.509105Z","shell.execute_reply.started":"2023-08-17T14:52:02.714523Z","shell.execute_reply":"2023-08-17T14:52:03.507885Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_622/1591327229.py:7: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  loss = F.cross_entropy(F.softmax(logits), labels)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_622/1591327229.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  predictions = F.softmax(torch.tensor(logits))\n/tmp/ipykernel_622/118270931.py:2: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  log_loss(temp[1], F.softmax(torch.tensor(temp[0])))\n","output_type":"stream"},{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"2.0555358235067267"},"metadata":{}}]},{"cell_type":"code","source":"data = []\n\nfor i in range(len(val_dataset)):\n    data.append([val_dataset[i]['PLAYER'], \n                 temp[1][i],\n                 F.softmax(torch.tensor(temp[0][i]))])\n    \nres = pd.DataFrame(data, columns=['PLAYER', 'TIER', 'pred'])\nres['label'] = res['TIER'].apply(lambda x: np.argmax(x))\nres['pred_label'] = res['pred'].apply(lambda x: np.sum([i*x[i] for i in range(5)]))\nres['diff'] = np.abs(res['label'] - res['pred_label'])\n\nres['log_loss'] = res[['TIER', 'pred']].apply(lambda x: log_loss(x[0], x[1]), \n                                              axis=1)\nres.sort_values('diff', ascending=False)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-17T14:52:03.511723Z","iopub.execute_input":"2023-08-17T14:52:03.512138Z","iopub.status.idle":"2023-08-17T14:52:03.791230Z","shell.execute_reply.started":"2023-08-17T14:52:03.512099Z","shell.execute_reply":"2023-08-17T14:52:03.789958Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_622/1643513749.py:6: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  F.softmax(torch.tensor(temp[0][i]))])\n","output_type":"stream"},{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"                    PLAYER                       TIER  \\\n27       Victor Wembanyama  [0.0, 0.0, 0.0, 0.0, 1.0]   \n34          Brandon Miller  [0.0, 0.0, 0.0, 0.0, 1.0]   \n28           Amen Thompson  [0.0, 0.0, 0.0, 0.0, 1.0]   \n6            Jarace Walker  [0.0, 0.0, 0.0, 1.0, 0.0]   \n16            Jaylen Clark  [1.0, 0.0, 0.0, 0.0, 0.0]   \n13        Julian Strawther  [1.0, 0.0, 0.0, 0.0, 0.0]   \n17              Nadir Hifi  [1.0, 0.0, 0.0, 0.0, 0.0]   \n7           Mike Miles Jr.  [1.0, 0.0, 0.0, 0.0, 0.0]   \n15             Isaiah Wong  [1.0, 0.0, 0.0, 0.0, 0.0]   \n4   Gregory “G.G.” Jackson  [0.0, 1.0, 0.0, 0.0, 0.0]   \n18           Anthony Black  [0.0, 0.0, 0.0, 1.0, 0.0]   \n22         Colin Castleton  [1.0, 0.0, 0.0, 0.0, 0.0]   \n24           Cason Wallace  [0.0, 0.0, 1.0, 0.0, 0.0]   \n5            Jalen Pickett  [1.0, 0.0, 0.0, 0.0, 0.0]   \n33        Dereck Lively II  [0.0, 0.0, 1.0, 0.0, 0.0]   \n3               Drew Timme  [1.0, 0.0, 0.0, 0.0, 0.0]   \n35             Kobe Bufkin  [0.0, 0.0, 1.0, 0.0, 0.0]   \n32           Jordan Miller  [1.0, 0.0, 0.0, 0.0, 0.0]   \n29        Jaime Jaquez Jr.  [0.0, 1.0, 0.0, 0.0, 0.0]   \n8            Marcus Sasser  [0.0, 1.0, 0.0, 0.0, 0.0]   \n11             James Nnaji  [1.0, 0.0, 0.0, 0.0, 0.0]   \n36          Mouhamed Gueye  [1.0, 0.0, 0.0, 0.0, 0.0]   \n19           Andre Jackson  [0.0, 1.0, 0.0, 0.0, 0.0]   \n21        Ricky Council IV  [1.0, 0.0, 0.0, 0.0, 0.0]   \n25             Kris Murray  [0.0, 1.0, 0.0, 0.0, 0.0]   \n1           Leonard Miller  [0.0, 0.0, 1.0, 0.0, 0.0]   \n20            Sidy Cissoko  [0.0, 1.0, 0.0, 0.0, 0.0]   \n31          Keyonte George  [0.0, 1.0, 0.0, 0.0, 0.0]   \n10            Jordan Walsh  [1.0, 0.0, 0.0, 0.0, 0.0]   \n0          Dariq Whitehead  [0.0, 1.0, 0.0, 0.0, 0.0]   \n38        Brice Sensabaugh  [0.0, 1.0, 0.0, 0.0, 0.0]   \n14           Maxwell Lewis  [0.0, 1.0, 0.0, 0.0, 0.0]   \n39       Landers Nolley II  [1.0, 0.0, 0.0, 0.0, 0.0]   \n26          Toumani Camara  [1.0, 0.0, 0.0, 0.0, 0.0]   \n23         Ąžuolas Tubelis  [1.0, 0.0, 0.0, 0.0, 0.0]   \n12         Caleb McConnell  [1.0, 0.0, 0.0, 0.0, 0.0]   \n9             Adama Sanogo  [1.0, 0.0, 0.0, 0.0, 0.0]   \n37             Mojave King  [1.0, 0.0, 0.0, 0.0, 0.0]   \n30            Rayan Rupert  [0.0, 1.0, 0.0, 0.0, 0.0]   \n2           Jordan Hawkins  [0.0, 1.0, 0.0, 0.0, 0.0]   \n\n                                                 pred  label  pred_label  \\\n27  [tensor(0.7119), tensor(0.2676), tensor(0.0171...      4    0.313782   \n34  [tensor(0.7032), tensor(0.2568), tensor(0.0372...      4    0.340951   \n28  [tensor(0.1694), tensor(0.4854), tensor(0.3389...      4    1.185596   \n6   [tensor(0.8302), tensor(0.1211), tensor(0.0087...      3    0.295974   \n16  [tensor(0.0082), tensor(0.0624), tensor(0.9162...      0    1.937290   \n13  [tensor(0.0199), tensor(0.0836), tensor(0.8887...      0    1.886750   \n17  [tensor(0.0129), tensor(0.1056), tensor(0.8707...      0    1.882588   \n7   [tensor(0.0310), tensor(0.1158), tensor(0.8459...      0    1.832067   \n15  [tensor(0.0281), tensor(0.1367), tensor(0.8266...      0    1.818207   \n4   [tensor(0.0058), tensor(0.1192), tensor(0.0210...      1    2.737038   \n18  [tensor(0.0573), tensor(0.6310), tensor(0.2879...      3    1.286396   \n22  [tensor(0.0849), tensor(0.2079), tensor(0.7004...      0    1.632333   \n24  [tensor(0.5067), tensor(0.4408), tensor(0.0487...      2    0.552006   \n5   [tensor(0.0686), tensor(0.5962), tensor(0.3217...      0    1.282552   \n33  [tensor(0.2748), tensor(0.6720), tensor(0.0478...      2    0.785637   \n3   [tensor(0.1118), tensor(0.7252), tensor(0.1525...      0    1.062886   \n35  [tensor(0.2170), tensor(0.6013), tensor(0.1769...      2    0.970752   \n32  [tensor(0.2505), tensor(0.5799), tensor(0.1653...      0    0.924969   \n29  [tensor(0.9257), tensor(0.0658), tensor(0.0058...      1    0.087391   \n8   [tensor(0.0229), tensor(0.0842), tensor(0.8854...      1    1.880299   \n11  [tensor(0.2433), tensor(0.6904), tensor(0.0618...      0    0.829646   \n36  [tensor(0.2947), tensor(0.6737), tensor(0.0242...      0    0.746233   \n19  [tensor(0.0335), tensor(0.2089), tensor(0.7478...      1    1.738125   \n21  [tensor(0.4278), tensor(0.4455), tensor(0.1230...      0    0.704240   \n25  [tensor(0.4166), tensor(0.5495), tensor(0.0296...      1    0.623327   \n1   [tensor(0.0601), tensor(0.2032), tensor(0.7292...      2    1.686642   \n20  [tensor(0.0899), tensor(0.5464), tensor(0.3530...      1    1.289632   \n31  [tensor(0.2615), tensor(0.6941), tensor(0.0389...      1    0.790051   \n10  [tensor(0.8705), tensor(0.1135), tensor(0.0106...      0    0.155726   \n0   [tensor(0.3312), tensor(0.4964), tensor(0.1681...      1    0.847707   \n38  [tensor(0.1999), tensor(0.7566), tensor(0.0368...      1    0.852420   \n14  [tensor(0.1551), tensor(0.6036), tensor(0.2349...      1    1.095124   \n39  [tensor(0.9251), tensor(0.0662), tensor(0.0053...      0    0.089151   \n26  [tensor(0.9340), tensor(0.0568), tensor(0.0052...      0    0.082695   \n23  [tensor(0.9331), tensor(0.0576), tensor(0.0065...      0    0.080885   \n12  [tensor(0.9345), tensor(0.0567), tensor(0.0062...      0    0.078870   \n9   [tensor(0.9389), tensor(0.0520), tensor(0.0071...      0    0.073927   \n37  [tensor(0.9461), tensor(0.0435), tensor(0.0054...      0    0.073617   \n30  [tensor(0.1208), tensor(0.8213), tensor(0.0401...      1    0.957206   \n2   [tensor(0.1579), tensor(0.6792), tensor(0.1575...      1    1.011841   \n\n        diff  log_loss  \n27  3.686218  1.585793  \n34  3.659049  1.626323  \n28  2.814404  1.384418  \n6   2.704026  1.582781  \n16  1.937290  1.473004  \n13  1.886750  1.241328  \n17  1.882588  1.303264  \n7   1.832067  1.095154  \n15  1.818207  1.095795  \n4   1.737038  0.800229  \n18  1.713604  1.113660  \n22  1.632333  0.782332  \n24  1.447994  0.862786  \n5   1.282552  0.797753  \n33  1.214363  0.896347  \n3   1.062886  0.731762  \n35  1.029248  0.580269  \n32  0.924969  0.487266  \n29  0.912609  1.065803  \n8   0.880299  0.934339  \n11  0.829646  0.530830  \n36  0.746233  0.474750  \n19  0.738125  0.597505  \n21  0.704240  0.314760  \n25  0.376673  0.234396  \n1   0.313358  0.122502  \n20  0.289632  0.228928  \n31  0.209949  0.142711  \n10  0.155726  0.055056  \n0   0.152293  0.258196  \n38  0.147580  0.109213  \n14  0.095124  0.189508  \n39  0.089151  0.031001  \n26  0.082695  0.027210  \n23  0.080885  0.027563  \n12  0.078870  0.027000  \n9   0.073927  0.025122  \n37  0.073617  0.022057  \n30  0.042794  0.076901  \n2   0.011841  0.147120  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PLAYER</th>\n      <th>TIER</th>\n      <th>pred</th>\n      <th>label</th>\n      <th>pred_label</th>\n      <th>diff</th>\n      <th>log_loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>27</th>\n      <td>Victor Wembanyama</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n      <td>[tensor(0.7119), tensor(0.2676), tensor(0.0171...</td>\n      <td>4</td>\n      <td>0.313782</td>\n      <td>3.686218</td>\n      <td>1.585793</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>Brandon Miller</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n      <td>[tensor(0.7032), tensor(0.2568), tensor(0.0372...</td>\n      <td>4</td>\n      <td>0.340951</td>\n      <td>3.659049</td>\n      <td>1.626323</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>Amen Thompson</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n      <td>[tensor(0.1694), tensor(0.4854), tensor(0.3389...</td>\n      <td>4</td>\n      <td>1.185596</td>\n      <td>2.814404</td>\n      <td>1.384418</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Jarace Walker</td>\n      <td>[0.0, 0.0, 0.0, 1.0, 0.0]</td>\n      <td>[tensor(0.8302), tensor(0.1211), tensor(0.0087...</td>\n      <td>3</td>\n      <td>0.295974</td>\n      <td>2.704026</td>\n      <td>1.582781</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Jaylen Clark</td>\n      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n      <td>[tensor(0.0082), tensor(0.0624), tensor(0.9162...</td>\n      <td>0</td>\n      <td>1.937290</td>\n      <td>1.937290</td>\n      <td>1.473004</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Julian Strawther</td>\n      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n      <td>[tensor(0.0199), tensor(0.0836), tensor(0.8887...</td>\n      <td>0</td>\n      <td>1.886750</td>\n      <td>1.886750</td>\n      <td>1.241328</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Nadir Hifi</td>\n      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n      <td>[tensor(0.0129), tensor(0.1056), tensor(0.8707...</td>\n      <td>0</td>\n      <td>1.882588</td>\n      <td>1.882588</td>\n      <td>1.303264</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Mike Miles Jr.</td>\n      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n      <td>[tensor(0.0310), tensor(0.1158), tensor(0.8459...</td>\n      <td>0</td>\n      <td>1.832067</td>\n      <td>1.832067</td>\n      <td>1.095154</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Isaiah Wong</td>\n      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n      <td>[tensor(0.0281), tensor(0.1367), tensor(0.8266...</td>\n      <td>0</td>\n      <td>1.818207</td>\n      <td>1.818207</td>\n      <td>1.095795</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Gregory “G.G.” Jackson</td>\n      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n      <td>[tensor(0.0058), tensor(0.1192), tensor(0.0210...</td>\n      <td>1</td>\n      <td>2.737038</td>\n      <td>1.737038</td>\n      <td>0.800229</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Anthony Black</td>\n      <td>[0.0, 0.0, 0.0, 1.0, 0.0]</td>\n      <td>[tensor(0.0573), tensor(0.6310), tensor(0.2879...</td>\n      <td>3</td>\n      <td>1.286396</td>\n      <td>1.713604</td>\n      <td>1.113660</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>Colin Castleton</td>\n      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n      <td>[tensor(0.0849), tensor(0.2079), tensor(0.7004...</td>\n      <td>0</td>\n      <td>1.632333</td>\n      <td>1.632333</td>\n      <td>0.782332</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>Cason Wallace</td>\n      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n      <td>[tensor(0.5067), tensor(0.4408), tensor(0.0487...</td>\n      <td>2</td>\n      <td>0.552006</td>\n      <td>1.447994</td>\n      <td>0.862786</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Jalen Pickett</td>\n      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n      <td>[tensor(0.0686), tensor(0.5962), tensor(0.3217...</td>\n      <td>0</td>\n      <td>1.282552</td>\n      <td>1.282552</td>\n      <td>0.797753</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>Dereck Lively II</td>\n      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n      <td>[tensor(0.2748), tensor(0.6720), tensor(0.0478...</td>\n      <td>2</td>\n      <td>0.785637</td>\n      <td>1.214363</td>\n      <td>0.896347</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Drew Timme</td>\n      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n      <td>[tensor(0.1118), tensor(0.7252), tensor(0.1525...</td>\n      <td>0</td>\n      <td>1.062886</td>\n      <td>1.062886</td>\n      <td>0.731762</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>Kobe Bufkin</td>\n      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n      <td>[tensor(0.2170), tensor(0.6013), tensor(0.1769...</td>\n      <td>2</td>\n      <td>0.970752</td>\n      <td>1.029248</td>\n      <td>0.580269</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>Jordan Miller</td>\n      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n      <td>[tensor(0.2505), tensor(0.5799), tensor(0.1653...</td>\n      <td>0</td>\n      <td>0.924969</td>\n      <td>0.924969</td>\n      <td>0.487266</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>Jaime Jaquez Jr.</td>\n      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n      <td>[tensor(0.9257), tensor(0.0658), tensor(0.0058...</td>\n      <td>1</td>\n      <td>0.087391</td>\n      <td>0.912609</td>\n      <td>1.065803</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Marcus Sasser</td>\n      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n      <td>[tensor(0.0229), tensor(0.0842), tensor(0.8854...</td>\n      <td>1</td>\n      <td>1.880299</td>\n      <td>0.880299</td>\n      <td>0.934339</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>James Nnaji</td>\n      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n      <td>[tensor(0.2433), tensor(0.6904), tensor(0.0618...</td>\n      <td>0</td>\n      <td>0.829646</td>\n      <td>0.829646</td>\n      <td>0.530830</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>Mouhamed Gueye</td>\n      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n      <td>[tensor(0.2947), tensor(0.6737), tensor(0.0242...</td>\n      <td>0</td>\n      <td>0.746233</td>\n      <td>0.746233</td>\n      <td>0.474750</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>Andre Jackson</td>\n      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n      <td>[tensor(0.0335), tensor(0.2089), tensor(0.7478...</td>\n      <td>1</td>\n      <td>1.738125</td>\n      <td>0.738125</td>\n      <td>0.597505</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>Ricky Council IV</td>\n      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n      <td>[tensor(0.4278), tensor(0.4455), tensor(0.1230...</td>\n      <td>0</td>\n      <td>0.704240</td>\n      <td>0.704240</td>\n      <td>0.314760</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>Kris Murray</td>\n      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n      <td>[tensor(0.4166), tensor(0.5495), tensor(0.0296...</td>\n      <td>1</td>\n      <td>0.623327</td>\n      <td>0.376673</td>\n      <td>0.234396</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Leonard Miller</td>\n      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n      <td>[tensor(0.0601), tensor(0.2032), tensor(0.7292...</td>\n      <td>2</td>\n      <td>1.686642</td>\n      <td>0.313358</td>\n      <td>0.122502</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>Sidy Cissoko</td>\n      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n      <td>[tensor(0.0899), tensor(0.5464), tensor(0.3530...</td>\n      <td>1</td>\n      <td>1.289632</td>\n      <td>0.289632</td>\n      <td>0.228928</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>Keyonte George</td>\n      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n      <td>[tensor(0.2615), tensor(0.6941), tensor(0.0389...</td>\n      <td>1</td>\n      <td>0.790051</td>\n      <td>0.209949</td>\n      <td>0.142711</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Jordan Walsh</td>\n      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n      <td>[tensor(0.8705), tensor(0.1135), tensor(0.0106...</td>\n      <td>0</td>\n      <td>0.155726</td>\n      <td>0.155726</td>\n      <td>0.055056</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Dariq Whitehead</td>\n      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n      <td>[tensor(0.3312), tensor(0.4964), tensor(0.1681...</td>\n      <td>1</td>\n      <td>0.847707</td>\n      <td>0.152293</td>\n      <td>0.258196</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>Brice Sensabaugh</td>\n      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n      <td>[tensor(0.1999), tensor(0.7566), tensor(0.0368...</td>\n      <td>1</td>\n      <td>0.852420</td>\n      <td>0.147580</td>\n      <td>0.109213</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Maxwell Lewis</td>\n      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n      <td>[tensor(0.1551), tensor(0.6036), tensor(0.2349...</td>\n      <td>1</td>\n      <td>1.095124</td>\n      <td>0.095124</td>\n      <td>0.189508</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>Landers Nolley II</td>\n      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n      <td>[tensor(0.9251), tensor(0.0662), tensor(0.0053...</td>\n      <td>0</td>\n      <td>0.089151</td>\n      <td>0.089151</td>\n      <td>0.031001</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>Toumani Camara</td>\n      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n      <td>[tensor(0.9340), tensor(0.0568), tensor(0.0052...</td>\n      <td>0</td>\n      <td>0.082695</td>\n      <td>0.082695</td>\n      <td>0.027210</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>Ąžuolas Tubelis</td>\n      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n      <td>[tensor(0.9331), tensor(0.0576), tensor(0.0065...</td>\n      <td>0</td>\n      <td>0.080885</td>\n      <td>0.080885</td>\n      <td>0.027563</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Caleb McConnell</td>\n      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n      <td>[tensor(0.9345), tensor(0.0567), tensor(0.0062...</td>\n      <td>0</td>\n      <td>0.078870</td>\n      <td>0.078870</td>\n      <td>0.027000</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Adama Sanogo</td>\n      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n      <td>[tensor(0.9389), tensor(0.0520), tensor(0.0071...</td>\n      <td>0</td>\n      <td>0.073927</td>\n      <td>0.073927</td>\n      <td>0.025122</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>Mojave King</td>\n      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n      <td>[tensor(0.9461), tensor(0.0435), tensor(0.0054...</td>\n      <td>0</td>\n      <td>0.073617</td>\n      <td>0.073617</td>\n      <td>0.022057</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>Rayan Rupert</td>\n      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n      <td>[tensor(0.1208), tensor(0.8213), tensor(0.0401...</td>\n      <td>1</td>\n      <td>0.957206</td>\n      <td>0.042794</td>\n      <td>0.076901</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Jordan Hawkins</td>\n      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n      <td>[tensor(0.1579), tensor(0.6792), tensor(0.1575...</td>\n      <td>1</td>\n      <td>1.011841</td>\n      <td>0.011841</td>\n      <td>0.147120</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"temp = trainer.predict(test_dataset)\nlog_loss(temp[1], F.softmax(torch.tensor(temp[0])))","metadata":{"execution":{"iopub.status.busy":"2023-08-17T14:52:03.793107Z","iopub.execute_input":"2023-08-17T14:52:03.793559Z","iopub.status.idle":"2023-08-17T14:52:04.501493Z","shell.execute_reply.started":"2023-08-17T14:52:03.793519Z","shell.execute_reply":"2023-08-17T14:52:04.500235Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_622/1591327229.py:7: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  loss = F.cross_entropy(F.softmax(logits), labels)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_622/1591327229.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  predictions = F.softmax(torch.tensor(logits))\n/tmp/ipykernel_622/1060597350.py:2: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  log_loss(temp[1], F.softmax(torch.tensor(temp[0])))\n","output_type":"stream"},{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"1.4478618176831581"},"metadata":{}}]},{"cell_type":"code","source":"data = []\n\nfor i in range(len(test_dataset)):\n    data.append([test_dataset[i]['PLAYER'], \n                 temp[1][i],\n                 F.softmax(torch.tensor(temp[0][i]))])\n    \nres = pd.DataFrame(data, columns=['PLAYER', 'TIER', 'pred'])\nres['label'] = res['TIER'].apply(lambda x: np.argmax(x))\nres['pred_label'] = res['pred'].apply(lambda x: np.sum([i*x[i] for i in range(5)]))\nres['diff'] = np.abs(res['label'] - res['pred_label'])\n\nres['log_loss'] = res[['TIER', 'pred']].apply(lambda x: log_loss(x[0], x[1]), \n                                              axis=1)\nres.sort_values('diff', ascending=False)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-17T14:52:04.503291Z","iopub.execute_input":"2023-08-17T14:52:04.504595Z","iopub.status.idle":"2023-08-17T14:52:04.764358Z","shell.execute_reply.started":"2023-08-17T14:52:04.504552Z","shell.execute_reply":"2023-08-17T14:52:04.763221Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_622/456294528.py:6: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  F.softmax(torch.tensor(temp[0][i]))])\n","output_type":"stream"},{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"                     PLAYER                       TIER  \\\n20          Scoot Henderson  [0.0, 0.0, 0.0, 0.0, 1.0]   \n29         Taylor Hendricks  [0.0, 0.0, 0.0, 1.0, 0.0]   \n19           Ausar Thompson  [0.0, 0.0, 0.0, 1.0, 0.0]   \n11         Terquavion Smith  [1.0, 0.0, 0.0, 0.0, 0.0]   \n16             Adam Flagler  [1.0, 0.0, 0.0, 0.0, 0.0]   \n10              Omari Moore  [1.0, 0.0, 0.0, 0.0, 0.0]   \n6           Tosan Evbuomwan  [1.0, 0.0, 0.0, 0.0, 0.0]   \n34           Nick Smith Jr.  [0.0, 1.0, 0.0, 0.0, 0.0]   \n28            Jaylen Martin  [1.0, 0.0, 0.0, 0.0, 0.0]   \n33               Kobe Brown  [0.0, 1.0, 0.0, 0.0, 0.0]   \n21             Jalen Wilson  [1.0, 0.0, 0.0, 0.0, 0.0]   \n27          Julian Phillips  [0.0, 1.0, 0.0, 0.0, 0.0]   \n32             Cam Whitmore  [0.0, 0.0, 0.0, 0.0, 1.0]   \n13       Brandin Podziemski  [1.0, 0.0, 0.0, 0.0, 0.0]   \n22     Trayce Jackson-Davis  [1.0, 0.0, 0.0, 0.0, 0.0]   \n14              Gradey Dick  [0.0, 0.0, 1.0, 0.0, 0.0]   \n3       Jalen Hood-Schifino  [0.0, 0.0, 1.0, 0.0, 0.0]   \n0          Tristan Vukčević  [1.0, 0.0, 0.0, 0.0, 0.0]   \n30          Bilal Coulibaly  [0.0, 0.0, 1.0, 0.0, 0.0]   \n7              Noah Clowney  [0.0, 1.0, 0.0, 0.0, 0.0]   \n2             Jalen Slawson  [1.0, 0.0, 0.0, 0.0, 0.0]   \n8               Jett Howard  [0.0, 1.0, 0.0, 0.0, 0.0]   \n17  Olivier-Maxence Prosper  [0.0, 1.0, 0.0, 0.0, 0.0]   \n31           Oscar Tshiebwe  [1.0, 0.0, 0.0, 0.0, 0.0]   \n26              Colby Jones  [0.0, 1.0, 0.0, 0.0, 0.0]   \n18          Sir’Jabari Rice  [1.0, 0.0, 0.0, 0.0, 0.0]   \n24             Ben Sheppard  [0.0, 1.0, 0.0, 0.0, 0.0]   \n9             Darius McGhee  [1.0, 0.0, 0.0, 0.0, 0.0]   \n5                Seth Lundy  [1.0, 0.0, 0.0, 0.0, 0.0]   \n25             Hunter Tyson  [1.0, 0.0, 0.0, 0.0, 0.0]   \n12          Charles Bediako  [1.0, 0.0, 0.0, 0.0, 0.0]   \n4               Emoni Bates  [1.0, 0.0, 0.0, 0.0, 0.0]   \n23             Liam Robbins  [1.0, 0.0, 0.0, 0.0, 0.0]   \n15         Chris Livingston  [1.0, 0.0, 0.0, 0.0, 0.0]   \n1              Amari Bailey  [1.0, 0.0, 0.0, 0.0, 0.0]   \n\n                                                 pred  label  pred_label  \\\n20  [tensor(0.0431), tensor(0.7755), tensor(0.1065...      4    1.219463   \n29  [tensor(0.7886), tensor(0.1779), tensor(0.0309...      3    0.249289   \n19  [tensor(0.0645), tensor(0.5663), tensor(0.3556...      3    1.320293   \n11  [tensor(0.1331), tensor(0.4393), tensor(0.4210...      0    1.304435   \n16  [tensor(0.0868), tensor(0.7317), tensor(0.1702...      0    1.109731   \n10  [tensor(0.1912), tensor(0.6729), tensor(0.1311...      0    0.950913   \n6   [tensor(0.1553), tensor(0.7776), tensor(0.0568...      0    0.923342   \n34  [tensor(0.9349), tensor(0.0532), tensor(0.0068...      1    0.086357   \n28  [tensor(0.1989), tensor(0.7115), tensor(0.0823...      0    0.900828   \n33  [tensor(0.9254), tensor(0.0616), tensor(0.0065...      1    0.100037   \n21  [tensor(0.2169), tensor(0.6885), tensor(0.0889...      0    0.884609   \n27  [tensor(0.9064), tensor(0.0710), tensor(0.0201...      1    0.120688   \n32  [tensor(0.0070), tensor(0.0972), tensor(0.0288...      4    3.126745   \n13  [tensor(0.2290), tensor(0.6955), tensor(0.0700...      0    0.854154   \n22  [tensor(0.2950), tensor(0.6007), tensor(0.1003...      0    0.814890   \n14  [tensor(0.1086), tensor(0.6072), tensor(0.2754...      2    1.186515   \n3   [tensor(0.0590), tensor(0.6404), tensor(0.2837...      2    1.261263   \n0   [tensor(0.3839), tensor(0.5813), tensor(0.0292...      0    0.657625   \n30  [tensor(0.0275), tensor(0.6752), tensor(0.0745...      2    1.499122   \n7   [tensor(0.0820), tensor(0.3741), tensor(0.5350...      1    1.474603   \n2   [tensor(0.6386), tensor(0.3321), tensor(0.0261...      0    0.395272   \n8   [tensor(0.0761), tensor(0.4936), tensor(0.4174...      1    1.370017   \n17  [tensor(0.0351), tensor(0.7355), tensor(0.1247...      1    1.302379   \n31  [tensor(0.7544), tensor(0.2294), tensor(0.0127...      0    0.266549   \n26  [tensor(0.3807), tensor(0.4660), tensor(0.1493...      1    0.778660   \n18  [tensor(0.8209), tensor(0.1674), tensor(0.0087...      0    0.195157   \n24  [tensor(0.0958), tensor(0.6566), tensor(0.2366...      1    1.166548   \n9   [tensor(0.8937), tensor(0.0958), tensor(0.0074...      0    0.122175   \n5   [tensor(0.9081), tensor(0.0777), tensor(0.0120...      0    0.109955   \n25  [tensor(0.9191), tensor(0.0696), tensor(0.0082...      0    0.097616   \n12  [tensor(0.9340), tensor(0.0540), tensor(0.0053...      0    0.090167   \n4   [tensor(0.9310), tensor(0.0598), tensor(0.0060...      0    0.083914   \n23  [tensor(0.9369), tensor(0.0540), tensor(0.0059...      0    0.077840   \n15  [tensor(0.9440), tensor(0.0449), tensor(0.0062...      0    0.076356   \n1   [tensor(0.9419), tensor(0.0484), tensor(0.0067...      0    0.073267   \n\n        diff  log_loss  \n20  2.780537  1.363497  \n29  2.750711  1.780604  \n19  1.679707  1.160513  \n11  1.304435  0.629695  \n16  1.109731  0.791578  \n10  0.950913  0.583439  \n6   0.923342  0.686937  \n34  0.913643  1.135529  \n28  0.900828  0.590215  \n33  0.899963  1.079301  \n21  0.884609  0.558689  \n27  0.879312  1.007244  \n32  0.873255  0.363115  \n13  0.854154  0.548269  \n22  0.814890  0.449719  \n14  0.813485  0.469542  \n3   0.738737  0.472046  \n0   0.657625  0.372655  \n30  0.500878  0.799883  \n7   0.474603  0.368654  \n2   0.395272  0.176328  \n8   0.370017  0.267661  \n17  0.302379  0.117272  \n31  0.266549  0.111739  \n26  0.221340  0.281675  \n18  0.195157  0.078452  \n24  0.166548  0.160465  \n9   0.122175  0.044726  \n5   0.109955  0.038321  \n25  0.097616  0.033553  \n12  0.090167  0.027153  \n4   0.083914  0.028482  \n23  0.077840  0.025978  \n15  0.076356  0.022954  \n1   0.073267  0.023847  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PLAYER</th>\n      <th>TIER</th>\n      <th>pred</th>\n      <th>label</th>\n      <th>pred_label</th>\n      <th>diff</th>\n      <th>log_loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>20</th>\n      <td>Scoot Henderson</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n      <td>[tensor(0.0431), tensor(0.7755), tensor(0.1065...</td>\n      <td>4</td>\n      <td>1.219463</td>\n      <td>2.780537</td>\n      <td>1.363497</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>Taylor Hendricks</td>\n      <td>[0.0, 0.0, 0.0, 1.0, 0.0]</td>\n      <td>[tensor(0.7886), tensor(0.1779), tensor(0.0309...</td>\n      <td>3</td>\n      <td>0.249289</td>\n      <td>2.750711</td>\n      <td>1.780604</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>Ausar Thompson</td>\n      <td>[0.0, 0.0, 0.0, 1.0, 0.0]</td>\n      <td>[tensor(0.0645), tensor(0.5663), tensor(0.3556...</td>\n      <td>3</td>\n      <td>1.320293</td>\n      <td>1.679707</td>\n      <td>1.160513</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Terquavion Smith</td>\n      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n      <td>[tensor(0.1331), tensor(0.4393), tensor(0.4210...</td>\n      <td>0</td>\n      <td>1.304435</td>\n      <td>1.304435</td>\n      <td>0.629695</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Adam Flagler</td>\n      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n      <td>[tensor(0.0868), tensor(0.7317), tensor(0.1702...</td>\n      <td>0</td>\n      <td>1.109731</td>\n      <td>1.109731</td>\n      <td>0.791578</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Omari Moore</td>\n      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n      <td>[tensor(0.1912), tensor(0.6729), tensor(0.1311...</td>\n      <td>0</td>\n      <td>0.950913</td>\n      <td>0.950913</td>\n      <td>0.583439</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Tosan Evbuomwan</td>\n      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n      <td>[tensor(0.1553), tensor(0.7776), tensor(0.0568...</td>\n      <td>0</td>\n      <td>0.923342</td>\n      <td>0.923342</td>\n      <td>0.686937</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>Nick Smith Jr.</td>\n      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n      <td>[tensor(0.9349), tensor(0.0532), tensor(0.0068...</td>\n      <td>1</td>\n      <td>0.086357</td>\n      <td>0.913643</td>\n      <td>1.135529</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>Jaylen Martin</td>\n      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n      <td>[tensor(0.1989), tensor(0.7115), tensor(0.0823...</td>\n      <td>0</td>\n      <td>0.900828</td>\n      <td>0.900828</td>\n      <td>0.590215</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>Kobe Brown</td>\n      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n      <td>[tensor(0.9254), tensor(0.0616), tensor(0.0065...</td>\n      <td>1</td>\n      <td>0.100037</td>\n      <td>0.899963</td>\n      <td>1.079301</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>Jalen Wilson</td>\n      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n      <td>[tensor(0.2169), tensor(0.6885), tensor(0.0889...</td>\n      <td>0</td>\n      <td>0.884609</td>\n      <td>0.884609</td>\n      <td>0.558689</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>Julian Phillips</td>\n      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n      <td>[tensor(0.9064), tensor(0.0710), tensor(0.0201...</td>\n      <td>1</td>\n      <td>0.120688</td>\n      <td>0.879312</td>\n      <td>1.007244</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>Cam Whitmore</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n      <td>[tensor(0.0070), tensor(0.0972), tensor(0.0288...</td>\n      <td>4</td>\n      <td>3.126745</td>\n      <td>0.873255</td>\n      <td>0.363115</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Brandin Podziemski</td>\n      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n      <td>[tensor(0.2290), tensor(0.6955), tensor(0.0700...</td>\n      <td>0</td>\n      <td>0.854154</td>\n      <td>0.854154</td>\n      <td>0.548269</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>Trayce Jackson-Davis</td>\n      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n      <td>[tensor(0.2950), tensor(0.6007), tensor(0.1003...</td>\n      <td>0</td>\n      <td>0.814890</td>\n      <td>0.814890</td>\n      <td>0.449719</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Gradey Dick</td>\n      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n      <td>[tensor(0.1086), tensor(0.6072), tensor(0.2754...</td>\n      <td>2</td>\n      <td>1.186515</td>\n      <td>0.813485</td>\n      <td>0.469542</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Jalen Hood-Schifino</td>\n      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n      <td>[tensor(0.0590), tensor(0.6404), tensor(0.2837...</td>\n      <td>2</td>\n      <td>1.261263</td>\n      <td>0.738737</td>\n      <td>0.472046</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Tristan Vukčević</td>\n      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n      <td>[tensor(0.3839), tensor(0.5813), tensor(0.0292...</td>\n      <td>0</td>\n      <td>0.657625</td>\n      <td>0.657625</td>\n      <td>0.372655</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>Bilal Coulibaly</td>\n      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n      <td>[tensor(0.0275), tensor(0.6752), tensor(0.0745...</td>\n      <td>2</td>\n      <td>1.499122</td>\n      <td>0.500878</td>\n      <td>0.799883</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Noah Clowney</td>\n      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n      <td>[tensor(0.0820), tensor(0.3741), tensor(0.5350...</td>\n      <td>1</td>\n      <td>1.474603</td>\n      <td>0.474603</td>\n      <td>0.368654</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Jalen Slawson</td>\n      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n      <td>[tensor(0.6386), tensor(0.3321), tensor(0.0261...</td>\n      <td>0</td>\n      <td>0.395272</td>\n      <td>0.395272</td>\n      <td>0.176328</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Jett Howard</td>\n      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n      <td>[tensor(0.0761), tensor(0.4936), tensor(0.4174...</td>\n      <td>1</td>\n      <td>1.370017</td>\n      <td>0.370017</td>\n      <td>0.267661</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Olivier-Maxence Prosper</td>\n      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n      <td>[tensor(0.0351), tensor(0.7355), tensor(0.1247...</td>\n      <td>1</td>\n      <td>1.302379</td>\n      <td>0.302379</td>\n      <td>0.117272</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>Oscar Tshiebwe</td>\n      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n      <td>[tensor(0.7544), tensor(0.2294), tensor(0.0127...</td>\n      <td>0</td>\n      <td>0.266549</td>\n      <td>0.266549</td>\n      <td>0.111739</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>Colby Jones</td>\n      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n      <td>[tensor(0.3807), tensor(0.4660), tensor(0.1493...</td>\n      <td>1</td>\n      <td>0.778660</td>\n      <td>0.221340</td>\n      <td>0.281675</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Sir’Jabari Rice</td>\n      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n      <td>[tensor(0.8209), tensor(0.1674), tensor(0.0087...</td>\n      <td>0</td>\n      <td>0.195157</td>\n      <td>0.195157</td>\n      <td>0.078452</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>Ben Sheppard</td>\n      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n      <td>[tensor(0.0958), tensor(0.6566), tensor(0.2366...</td>\n      <td>1</td>\n      <td>1.166548</td>\n      <td>0.166548</td>\n      <td>0.160465</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Darius McGhee</td>\n      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n      <td>[tensor(0.8937), tensor(0.0958), tensor(0.0074...</td>\n      <td>0</td>\n      <td>0.122175</td>\n      <td>0.122175</td>\n      <td>0.044726</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Seth Lundy</td>\n      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n      <td>[tensor(0.9081), tensor(0.0777), tensor(0.0120...</td>\n      <td>0</td>\n      <td>0.109955</td>\n      <td>0.109955</td>\n      <td>0.038321</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>Hunter Tyson</td>\n      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n      <td>[tensor(0.9191), tensor(0.0696), tensor(0.0082...</td>\n      <td>0</td>\n      <td>0.097616</td>\n      <td>0.097616</td>\n      <td>0.033553</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Charles Bediako</td>\n      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n      <td>[tensor(0.9340), tensor(0.0540), tensor(0.0053...</td>\n      <td>0</td>\n      <td>0.090167</td>\n      <td>0.090167</td>\n      <td>0.027153</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Emoni Bates</td>\n      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n      <td>[tensor(0.9310), tensor(0.0598), tensor(0.0060...</td>\n      <td>0</td>\n      <td>0.083914</td>\n      <td>0.083914</td>\n      <td>0.028482</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>Liam Robbins</td>\n      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n      <td>[tensor(0.9369), tensor(0.0540), tensor(0.0059...</td>\n      <td>0</td>\n      <td>0.077840</td>\n      <td>0.077840</td>\n      <td>0.025978</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Chris Livingston</td>\n      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n      <td>[tensor(0.9440), tensor(0.0449), tensor(0.0062...</td>\n      <td>0</td>\n      <td>0.076356</td>\n      <td>0.076356</td>\n      <td>0.022954</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Amari Bailey</td>\n      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n      <td>[tensor(0.9419), tensor(0.0484), tensor(0.0067...</td>\n      <td>0</td>\n      <td>0.073267</td>\n      <td>0.073267</td>\n      <td>0.023847</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}